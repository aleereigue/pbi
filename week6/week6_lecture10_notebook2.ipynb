{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming for Biomedical Informatics\n",
    "#### Week 6 - Differential Gene Expression Analysis\n",
    "\n",
    "We're going to perform some differential expression analysis using the PyDESeq2 package using an RNA-Seq dataset from NCBI-GEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sources of Data\n",
    "\n",
    "Original Publication\n",
    "Tomaiuolo P, Piras IS, Sain SB, Picinelli C, Baccarin M, Castronovo P, Morelli MJ, Lazarevic D, Scattoni ML, Tonon G, Persico AM.\n",
    "RNA sequencing of blood from sex- and age-matched discordant siblings supports immune and transcriptional dysregulation in autism spectrum disorder.\n",
    "Sci Rep. 2023 Jan 16;13(1):807. doi: 10.1038/s41598-023-27378-w. PMID: 36646776; PMCID: PMC9842630.\n",
    "\n",
    "GEO Entry: GSE212645\n",
    "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE212645\n",
    "\n",
    "meta-data file\n",
    "https://ftp.ncbi.nlm.nih.gov/geo/series/GSE212nnn/GSE212645/matrix/GSE212645_series_matrix.txt.gz\n",
    "\n",
    "raw data file\n",
    "https://www.ncbi.nlm.nih.gov/geo/download/?type=rnaseq_counts&acc=GSE212645&format=file&file=GSE212645_filtered_counts_GRCh38.p13_NCBI.tsv.gz\n",
    "\n",
    "normalised data file\n",
    "https://www.ncbi.nlm.nih.gov/geo/download/?type=rnaseq_counts&acc=GSE212645&format=file&file=GSE212645_norm_counts_FPKM_GRCh38.p13_NCBI.tsv.gz\n",
    "\n",
    "genome annotation file\n",
    "https://www.ncbi.nlm.nih.gov/geo/download/?format=file&type=rnaseq_counts&file=Human.GRCh38.p13.annot.tsv.gz\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the experimental data and meta-data\n",
    "\n",
    "#setup\n",
    "import urllib.request\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# #fetch the count data\n",
    "# counts_url = 'https://www.ncbi.nlm.nih.gov/geo/download/?type=rnaseq_counts&acc=GSE212645&format=file&file=GSE212645_filtered_counts_GRCh38.p13_NCBI.tsv.gz'\n",
    "# urllib.request.urlretrieve(counts_url, './data/GSE212645_filtered_counts_GRCh38.p13_NCBI.tsv.gz')\n",
    "raw_counts = pd.read_csv('./data/GSE212645_raw_counts_GRCh38.p13_NCBI.tsv.gz', sep='\\t', index_col=0)\n",
    "\n",
    "# #fetch the meta-data\n",
    "# metadata_url = 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE212nnn/GSE212645/matrix/GSE212645_series_matrix.txt.gz'\n",
    "# urllib.request.urlretrieve(metadata_url, './data/GSE212645_series_matrix.txt.gz')\n",
    "#read in the meta-data\n",
    "# we need to skip the first 38 rows as they contain project rather than sample meta-data\n",
    "metadata = pd.read_csv('./data/GSE212645_series_matrix.txt.gz', sep='\\t', skiprows=38, header=None)\n",
    "\n",
    "\n",
    "# we now tidy this up and retain the information we need\n",
    "# keep the rows we need\n",
    "row_numbers = [0,8,10,11,12]\n",
    "metadata = metadata.iloc[row_numbers]\n",
    "\n",
    "# replace column 0 values with the list below\n",
    "new_feature_names = ['number','gender', 'status', 'family', 'treatment']\n",
    "metadata.iloc[:,0] = new_feature_names\n",
    "\n",
    "# make the first row the column names and remove the first row\n",
    "metadata.columns = metadata.iloc[0]\n",
    "metadata = metadata.iloc[1:]\n",
    "metadata.set_index('number', append=False, inplace=True)\n",
    "\n",
    "# # transpose the data frame\n",
    "metadata = metadata.T\n",
    "\n",
    "# # reset the index and rename the first column\n",
    "metadata.reset_index(inplace=True)\n",
    "metadata.rename(columns={0: 'sample_no'}, inplace=True)\n",
    "\n",
    "# tidy up the column contents\n",
    "metadata['gender'] = metadata['gender'].str.replace('Sex: ', '')\n",
    "metadata['status'] = metadata['status'].str.replace('genotype: ', '')\n",
    "metadata['family'] = metadata['family'].str.replace('family: ', '')\n",
    "metadata['treatment'] = metadata['treatment'].str.replace('treatment: ', '')\n",
    "\n",
    "metadata.set_index('sample_no', inplace=True)\n",
    "metadata.index.name = None\n",
    "\n",
    "#change index name to sample_id\n",
    "metadata.index.name = 'sample_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only genes where all samples have counts >= 10\n",
    "filtered_counts = raw_counts[(raw_counts >= 10).all(axis=1)]\n",
    "\n",
    "# keep the mean counts of the removed genes to check later\n",
    "removed_counts = raw_counts[(raw_counts <= 10).all(axis=1)]\n",
    "\n",
    "# calculate the mean expression for each gene\n",
    "removed_means = removed_counts.mean(axis=1)\n",
    "removed_means = removed_means.sort_values(ascending=False)\n",
    "\n",
    "#keep this for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the count data\n",
    "print(filtered_counts.shape)\n",
    "filtered_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the meta-data\n",
    "print(metadata.shape)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a boxplot of the raw counts by sample\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "filtered_counts.boxplot(rot=90)\n",
    "plt.yscale('log')\n",
    "plt.title('Raw Gene Counts by Sample')\n",
    "plt.ylabel('log(Raw Counts)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an MA plot of the raw counts from scratch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# find all the columns in filtered_counts that have column headers matching the metadata index and have staus of 'ASD'ArithmeticError\n",
    "asd_samples = metadata[metadata['status'] == 'ASD'].index\n",
    "\n",
    "# find all the columns in filtered_counts that have column headers matching the metadata index and have staus of 'SIB'\n",
    "sib_samples = metadata[metadata['status'] == 'SIB'].index\n",
    "\n",
    "# calculate the mean of the raw counts for each gene in the ASD samples\n",
    "asd_mean = filtered_counts[asd_samples].mean(axis=1)\n",
    "\n",
    "# calculate the mean of the raw counts for each gene in the SIB samples\n",
    "sib_mean = filtered_counts[sib_samples].mean(axis=1)\n",
    "\n",
    "# create a new data frame with these mean values and the gene names as the index\n",
    "ma_data = pd.DataFrame({'ASD': asd_mean, 'SIB': sib_mean})\n",
    "\n",
    "# calculate the M value with log2\n",
    "ma_data['M'] = ma_data['ASD'].apply(np.log2) - ma_data['SIB'].apply(np.log2)\n",
    "\n",
    "# calculate the A value with log2\n",
    "ma_data['A'] = (ma_data['ASD'].apply(np.log2) + ma_data['SIB'].apply(np.log2)) / 2\n",
    "\n",
    "# plot the data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(ma_data['A'], ma_data['M'], s=1)\n",
    "plt.xlabel('A')\n",
    "plt.ylabel('M')\n",
    "plt.title('MA Plot of Raw Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple PCA analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "transposed_filtered_counts = filtered_counts.T\n",
    "\n",
    "# scale features, run PCA on 2-dimensions\n",
    "X = transposed_filtered_counts.values\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "pcs = pca.fit_transform(X_scaled)\n",
    "sample_pca = pd.DataFrame(pcs, columns=['PC1', 'PC2'], index=transposed_filtered_counts.index)\n",
    "\n",
    "sample_pca = sample_pca.join(metadata['status'])\n",
    "\n",
    "#visualise\n",
    "sample_pca.index.name = 'sample_id'\n",
    "\n",
    "print(sample_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the pca\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# map statuses to distinct colors\n",
    "statuses = list(sample_pca['status'].unique())\n",
    "cmap = plt.get_cmap('Set1')\n",
    "color_map = {s: cmap(i % cmap.N) for i, s in enumerate(statuses)}\n",
    "colors = sample_pca['status'].map(color_map)\n",
    "\n",
    "# create figure and axes, scatter and attach colorbar to that axes\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "sc = ax.scatter(sample_pca['PC1'], sample_pca['PC2'], s=50, edgecolor='k',c=list(colors))\n",
    "\n",
    "# simple legend with colored patches\n",
    "legend_elements = [Patch(facecolor=col, edgecolor='k', label=label) \n",
    "                   for label, col in color_map.items()]\n",
    "ax.legend(handles=legend_elements, title='status')\n",
    "\n",
    "# labels and colorbar\n",
    "ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "ax.set_title('PCA')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the outlier samples\n",
    "samples_to_remove = ['GSM6542253', 'GSM6542277']\n",
    "\n",
    "filtered_counts_good_samples = filtered_counts.drop(columns=samples_to_remove, errors='ignore')\n",
    "print(filtered_counts_good_samples.shape)\n",
    "\n",
    "metadata_good_samples = metadata.drop(index=samples_to_remove, errors='ignore')\n",
    "print(metadata_good_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets use DESeq2 to perform differential expression\n",
    "\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.default_inference import DefaultInference\n",
    "from pydeseq2.ds import DeseqStats\n",
    "from pydeseq2.utils import *\n",
    "\n",
    "SAVE = False  # whether to save the outputs of this notebook\n",
    "\n",
    "if SAVE:\n",
    "    # Replace this with the path to directory where you would like results to be\n",
    "    # saved\n",
    "    OUTPUT_PATH = \"./data/asd_deseq2_results\"\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)  # Create path if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up the DESeq2 object\n",
    "## Note we are setting up a two-factor (paired analysis) where disease status is assessed in sibling pairs affected:unaffected\n",
    "\n",
    "inference = DefaultInference(n_cpus=8)\n",
    "dds = DeseqDataSet(\n",
    "    counts=filtered_counts_good_samples.T,\n",
    "    metadata=metadata_good_samples,\n",
    "    design=\"~status+family\",\n",
    "    refit_cooks=True,\n",
    "    inference=inference,\n",
    ")\n",
    "\n",
    "#ignore the error, this is just because the gene_ids are numbers\n",
    "\n",
    "print(dds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute normalisation factors\n",
    "dds.fit_size_factors()\n",
    "\n",
    "# extract the size factors to look at\n",
    "size_factors = dds.obs[\"size_factors\"]\n",
    "\n",
    "# sort by value descending\n",
    "size_factors.sort_values()\n",
    "\n",
    "size_factors.columns = ['sizefactor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit gene-wise dispersion estimates\n",
    "dds.fit_genewise_dispersions()\n",
    "\n",
    "# fit dispersion priors\n",
    "dds.fit_dispersion_prior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at the DESeq2 object after the fitting\n",
    "print(dds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fitted dispersion trend\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(dds.var['genewise_dispersions'], dds.var['fitted_dispersions'])\n",
    "# plt.scatter(dds.var['genewise_dispersions'], dds.var['fitted_dispersions'])\n",
    "plt.xlabel('Gene-wise Dispersion')\n",
    "plt.ylabel('Fitted Dispersion')\n",
    "plt.title('Fitted Dispersion vs Gene-wise Dispersion')\n",
    "plt.show()\n",
    "\n",
    "# OK this looks very problematic, remember fitted vs gene dispersion should be a linear relationship - this is a red flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit log fold changes\n",
    "dds.fit_LFC()\n",
    "lfcs = dds.varm[\"LFC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved plot for log fold changes using seaborn style\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# flatten lfcs if it's an array-like\n",
    "lfcs_arr = np.array(lfcs).ravel()\n",
    "\n",
    "# compute robust x-limits (1st to 99th percentiles) to avoid extreme outliers\n",
    "vmin = np.nanpercentile(lfcs_arr, 1)\n",
    "vmax = np.nanpercentile(lfcs_arr, 99)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# plot histogram with KDE overlay, clipped to the percentile range for display\n",
    "sns.histplot(lfcs_arr, bins=200, kde=True, stat='density', color='C0')\n",
    "plt.xlim(vmin, vmax)\n",
    "\n",
    "# annotate mean and median\n",
    "mean_val = np.nanmean(lfcs_arr)\n",
    "median_val = np.nanmedian(lfcs_arr)\n",
    "plt.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean = {mean_val:.3f}')\n",
    "plt.axvline(median_val, color='green', linestyle='-.', linewidth=2, label=f'Median = {median_val:.3f}')\n",
    "\n",
    "plt.xlabel('Log Fold Change')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Log Fold Changes (clipped 1st-99th percentiles)')\n",
    "plt.legend()\n",
    "\n",
    "# add a small text box with summary stats\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "plt.text(0.95, 0.95, f'n={lfcs_arr.size}\\nmean={mean_val:.3f}\\nmedian={median_val:.3f}', transform=plt.gca().transAxes, fontsize=10, verticalalignment='top', horizontalalignment='right', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cooks distanes and refit\n",
    "\n",
    "# this step aims to identify outliers that would adversely affect the differential expresison analysis and filters them out\n",
    "dds.calculate_cooks()\n",
    "if dds.refit_cooks:\n",
    "    # Replace outlier counts\n",
    "    dds.refit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the dispersion plot\n",
    "dds.plot_dispersions()\n",
    "\n",
    "# this looks OK, but is very flat, an unusually low amount of dispersion especially at the high count end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results so far\n",
    "if SAVE:\n",
    "    with open(os.path.join(OUTPUT_PATH, \"dds_detailed_pipe.pkl\"), \"wb\") as f:\n",
    "        pkl.dump(dds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the main step where the differential expression is calculated\n",
    "stat_res = DeseqStats(dds, contrast=['status','ASD','SIB'], inference=inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the summary stats\n",
    "# runs the Wald test\n",
    "# this test effectively calculates the robustness of the beta value estaimation in the main DESeq2 GLM and then calculates the p-values based on the aussume\n",
    "# assumed normal distribution of the beta values\n",
    "\n",
    "stat_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = stat_res.results_df\n",
    "\n",
    "sorted_results = results.sort_values(by='pvalue', ascending=True)\n",
    "\n",
    "#convert the GeneID column to integers\n",
    "sorted_results.index = sorted_results.index.map(int)\n",
    "sorted_results.reset_index(inplace=True)\n",
    "\n",
    "sorted_results.head()\n",
    "\n",
    "# it's clear here that the p-value adjustment is very heavily penalising the p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally save the results\n",
    "# if SAVE:\n",
    "#     with open(os.path.join(OUTPUT_PATH, \"stat_results_detailed_pipe.pkl\"), \"wb\") as f:\n",
    "#         pkl.dump(stat_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the genome annotation file so that we can look at the gene names\n",
    "\n",
    "annotation_url = 'https://www.ncbi.nlm.nih.gov/geo/download/?format=file&type=rnaseq_counts&file=Human.GRCh38.p13.annot.tsv.gz'\n",
    "\n",
    "# download the file and save in the ./data directory\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "urllib.request.urlretrieve(annotation_url, './data/Human.GRCh38.p13.annot.tsv.gz')\n",
    "\n",
    "#read directly into a data frame\n",
    "annotation = pd.read_csv('./data/Human.GRCh38.p13.annot.tsv.gz', sep='\\t', index_col=0, low_memory=False)\n",
    "\n",
    "#drop all columns except Symbol and Description\n",
    "annotation = annotation[['Symbol', 'Description']]\n",
    "\n",
    "annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the annotation with the results on the GeneID column\n",
    "results = sorted_results.merge(annotation, left_on='GeneID', right_on='GeneID')\n",
    "\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets go back and pick up the results for the genes cited in the paper to see what the p-values are\n",
    "target_genes = ['EGR1', 'EGR2', 'IGKV6D-21', 'IGKV3D-15', 'S100B', 'CD80']\n",
    "\n",
    "target_gene_results = results[results['Symbol'].isin(target_genes)]\n",
    "\n",
    "target_gene_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets go back and find the log normlised counts for these genes\n",
    "# merge the ma_data with the target_gene_results on the GeneID column\n",
    "\n",
    "combined = target_gene_results.merge(ma_data, left_on='GeneID', right_index=True)\n",
    "\n",
    "combined.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can only display data from genes that made it through our earlier QC\n",
    "surviving_target_genes = set(target_genes) & set(combined['Symbol'])\n",
    "missing_genes = set(target_genes) - set(combined['Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of interest here are the mean counts for the target genes that were excluded earlier!\n",
    "\n",
    "# Filter annotation to find genes in missing_genes\n",
    "missing_gene_info = annotation[annotation['Symbol'].isin(list(missing_genes))]\n",
    "missing_gene_counts = pd.merge(missing_gene_info,raw_counts,on='GeneID')\n",
    "\n",
    "# Calculate mean of columns from the 3rd column onwards (columns 2+, 0-indexed)\n",
    "missing_gene_counts['Mean'] = missing_gene_counts.iloc[:, 2:].mean(axis=1)\n",
    "\n",
    "# Display the results\n",
    "print(missing_gene_counts[['Symbol', 'Mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we plot paired barcharts for each Symbol showing the log normalised counts for each gene in the ASD and SIB samples using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, len(surviving_target_genes), figsize=(20, 6))\n",
    "\n",
    "for i, gene in enumerate(surviving_target_genes):\n",
    "    #take the log2 values of the counts\n",
    "    combined.loc[combined['Symbol'] == gene, ['ASD', 'SIB']] = combined.loc[combined['Symbol'] == gene, ['ASD', 'SIB']].apply(np.log2)\n",
    "    ax[i].bar(['ASD', 'SIB'], combined.loc[combined['Symbol'] == gene, ['ASD', 'SIB']].values[0])\n",
    "    ax[i].set_title(gene)\n",
    "    ax[i].set_ylabel('log normalised counts')\n",
    "    ax[i].set_xlabel('Status')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# the trends are the same as in the paper, but the p-values are not significant - NB in the paper only EGR1 and IGKV3D-15 were significant after correction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
